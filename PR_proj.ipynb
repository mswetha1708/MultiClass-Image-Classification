{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PR_proj",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swethamohan1/MultiClass-Image-Classification/blob/master/PR_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J282OnZQenoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "3a50d758-c08a-4282-c8d8-4079697c218a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Dropout,Lambda\n",
        "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# from zipfile import ZipFile\n",
        "# with ZipFile('./drive/My Drive/seg_test.zip', 'r') as zipObj:\n",
        "#    # Extract all the contents of zip file in current directory\n",
        "#    zipObj.extractall()\n",
        "# with ZipFile('./drive/My Drive/seg_train.zip', 'r') as zipObj:\n",
        "#    # Extract all the contents of zip file in current directory\n",
        "#    zipObj.extractall()\n",
        "\n",
        "train_dir = './seg_train/'\n",
        "test_dir = './seg_test/'\n",
        "\n",
        "datagen = ImageDataGenerator( rescale=1.0/255.,\n",
        "                                    shear_range=0.2,  \n",
        "                                    zoom_range=0.2,        \n",
        "                                    horizontal_flip=True,\n",
        "                                    validation_split=0.3)\n",
        "train_gen= datagen.flow_from_directory(train_dir,\n",
        "                                        batch_size=8,\n",
        "                                        class_mode='categorical',\n",
        "                                        target_size=(150, 150))\n",
        "\n",
        "test_gen = datagen.flow_from_directory(test_dir,\n",
        "                                        batch_size=8,\n",
        "                                        class_mode='categorical',\n",
        "                                        target_size=(150, 150))\n",
        "\n",
        "def CNN_arch():\n",
        "    model = Sequential()\n",
        "    model.add(Lambda(lambda x: x, input_shape=(150, 150, 3)))\n",
        "\n",
        "    model.add(SeparableConv2D(16, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(SeparableConv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(SeparableConv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(SeparableConv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(6,activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "model = CNN_arch()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 14034 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_6 (Lambda)            (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_13 (Separab (None, 148, 148, 16)      91        \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 148, 148, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_14 (Separab (None, 72, 72, 32)        688       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 72, 72, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_15 (Separab (None, 34, 34, 64)        2400      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 34, 34, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_16 (Separab (None, 15, 15, 128)       8896      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 15, 15, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 6,442,737\n",
            "Trainable params: 6,442,257\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djpg0arInRuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "ef5851fd-e4e0-421d-a437-20c0f980c5c3"
      },
      "source": [
        "opt = SGD(lr=1e-4,momentum=0.99)\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "    \n",
        "history = model.fit_generator(\n",
        "    train_gen, \n",
        "    steps_per_epoch  = 150, \n",
        "    validation_data  = test_gen,\n",
        "    validation_steps = 150,\n",
        "    epochs = 5, \n",
        "    verbose = 1\n",
        ")\n",
        "model_score = model.evaluate_generator(test_gen)\n",
        "print(\"Model Test Loss:\",model_score[0])\n",
        "print(\"Model Test Accuracy:\",model_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "150/150 [==============================] - 14s 93ms/step - loss: 0.3139 - accuracy: 0.8719 - val_loss: 0.3090 - val_accuracy: 0.8361\n",
            "Epoch 2/5\n",
            "150/150 [==============================] - 13s 89ms/step - loss: 0.3172 - accuracy: 0.8651 - val_loss: 0.4884 - val_accuracy: 0.8861\n",
            "Epoch 3/5\n",
            "150/150 [==============================] - 13s 90ms/step - loss: 0.2889 - accuracy: 0.8790 - val_loss: 0.3462 - val_accuracy: 0.8649\n",
            "Epoch 4/5\n",
            "150/150 [==============================] - 13s 88ms/step - loss: 0.2948 - accuracy: 0.8772 - val_loss: 0.1696 - val_accuracy: 0.8889\n",
            "Epoch 5/5\n",
            "150/150 [==============================] - 13s 88ms/step - loss: 0.2947 - accuracy: 0.8772 - val_loss: 0.4070 - val_accuracy: 0.8712\n",
            "Model Test Loss: 0.3967212438583374\n",
            "Model Test Accuracy: 0.8723332285881042\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}